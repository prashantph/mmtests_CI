###
### Measure latency of reads in presence of sequential buffered write
###
### Run 1 writer thread doing large sequential write
### Run 1 reader thread doing random 4k reads from 20 different files
###
### This fio workload simulates application startup by reading randomly 4k
### chunks from 20 different files. We also run a writer thread doing large
### buffered sequential write. This is to see whether reads are not starved
### by flusher submitting large IOs asynchronously.
###

# MM Test Parameters
export MMTESTS="fio"

# Test disk to setup (optional)
#export TESTDISK_RAID_DEVICES=
#export TESTDISK_RAID_MD_DEVICE=/dev/md0
#export TESTDISK_RAID_OFFSET=63
#export TESTDISK_RAID_SIZE=250019532
#export TESTDISK_RAID_TYPE=raid0
#export TESTDISK_PARTITION=/dev/sda6
#export TESTDISK_FILESYSTEM=xfs
#export TESTDISK_MKFS_PARAM="-f -d agcount=8"
#export TESTDISK_MOUNT_ARGS=inode64,delaylog,logbsize=262144,nobarrier

# List of monitors
export RUN_MONITOR=yes
export MONITORS_ALWAYS=
export MONITORS_GZIP="proc-vmstat top"
export MONITORS_WITH_LATENCY="vmstat iostat"
export MONITOR_UPDATE_FREQUENCY=10

# fio
JOBFILE="/tmp/fio-jobfile-$$"
export FIO_CMD_OPTIONS="$JOBFILE"

cat >$JOBFILE <<END
[global]
direct=0
ioengine=sync
runtime=300
blocksize=4096
invalidate=1
time_based
ramp_time=5	# Let the flusher thread start before taking measurements
log_avg_msec=10
group_reporting=1

[writer]
nrfiles=1
filesize=$((MEMTOTAL_BYTES*2))
readwrite=write

[reader]
# Simulate random reading from different files, switching to different file
# after 16 ios. This somewhat simulates application startup.
new_group
filesize=100m
nrfiles=20
file_service_type=random:16
readwrite=randread
END
