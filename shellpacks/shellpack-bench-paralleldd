#!/bin/bash
# This benchmark runs varying numbers of dd instances on a single file to
# read and writing to multiple output files. A basic usage is to test if
# multiple processes can read from a file quickly or if they collide in
# strange ways. A secondary use is a mixed read/write benchmark.
P=paralleldd-bench
DEFAULT_VERSION=0
. $SHELLPACK_INCLUDE/common.sh
TIME_CMD=`which time`
if [ "$TIME_CMD" = "" ]; then
        TIMEFORMAT="%2Uuser %2Ssystem %Relapsed %P%%CPU"
        TIME_CMD="time"
fi
SRCTAR=
SRCTAR_EXTRA=
TARGETSIZE_MB=
NUMCPUS=$(grep -c '^processor' /proc/cpuinfo)
ITERATIONS=5
CONV=
PARALLELDD_WRITEFILES=

# Basic argument parser
TASKSET_SERVER=
TASKSET_CLIENT=
TASKSET_ALL=
SERVERSIDE_COMMAND=none
SERVERSIDE_NAME=`date +%Y%m%d-%H%M-%S`

while [ "$1" != "" ]; do
	case "$1" in
	-v)
		VERSION=$2
		shift 2
		;;
	--serverside-command)
		SERVERSIDE_COMMAND=$2
		shift 2
		;;
	--serverside-name)
		SERVERSIDE_NAME=$2
		shift 2
		;;
	--sourcesize)
		PARALLELDD_SOURCESIZE=$2
		shift 2
		;;
	--min-threads)
		PARALLELDD_MIN_THREADS=$2
		shift 2
		;;
	--max-threads)
		PARALLELDD_MAX_THREADS=$2
		shift 2
		;;
	--iterations)
		PARALLELDD_ITERATIONS=$2
		shift 2
		;;
	--write-files)
		PARALLELDD_WRITEFILES=yes
		shift
		;;
	--split-input)
		PARALLELDD_SPLITINPUT=yes
		shift
		;;
	*)
		echo Unrecognised option: $1
		shift
	esac
done
if [ "$TASKSET_SERVER" != "" ]; then
	echo TASKSET_SERVER: $TASKSET_SERVER
	echo TASKSET_CLIENT: $TASKSET_CLIENT
fi
if [ -z "$VERSION" ]; then
	VERSION=$DEFAULT_VERSION
fi
# Include monitor hooks
. $SHELLPACK_INCLUDE/include-monitor.sh
if [ "$INSTALL_ONLY" = "yes" ]; then
	echo paralleldd installed only as requested.
	exit $SHELLPACK_SUCCESS
fi

if [ "$PARALLELDD_SPLITINPUT" != "yes" ]; then
	create_random_file $PARALLELDD_SOURCESIZE $SHELLPACK_DATA/source_file
	sync
fi

THREADS=
START_THREAD=$PARALLELDD_MIN_THREADS
END_THREAD=$PARALLELDD_MAX_THREADS
if [ $END_THREAD -gt 32 ]; then
	THREADS=`seq $START_THREAD 3 8`
	THREADS="$THREADS `seq 12 9 32`"
	THREADS="$THREADS `seq 48 31 $END_THREAD`"
elif [ $END_THREAD -gt 8 ]; then
	THREADS=`seq $START_THREAD 2 8`
	THREADS="$THREADS `seq 12 6 $END_THREAD`"
else
	THREADS=`seq $START_THREAD 2 $END_THREAD`
fi
if [ `echo $THREADS | awk '{print $NF}'` -ne $END_THREAD ]; then
	THREADS="$THREADS $END_THREAD"
fi

for NR_THREADS in $THREADS; do
	if [ $NR_THREADS -lt $PARALLELDD_MIN_THREADS ]; then
		continue
	fi
	if [ "$MMTESTS_THREAD_CUTOFF" != "" ]; then
		if [ $NR_THREADS -gt $MMTESTS_THREAD_CUTOFF ]; then
			echo Forcing PARALLELDD_MAX_THREADS to $MMTESTS_THREAD_CUTOFF
			continue
		fi
	fi
	if [ "$PARALLELDD_SPLITINPUT" = "yes" ]; then
		create_random_file $((PARALLELDD_SOURCESIZE/$NR_THREADS)) $SHELLPACK_DATA/source_file.1
		for INSTANCE in `seq 2 $NR_THREADS`; do
			cp $SHELLPACK_DATA/source_file.1 $SHELLPACK_DATA/source_file.$INSTANCE
		done
		sync
	fi

	monitor_pre_hook $LOGDIR_RESULTS $NR_THREADS
for ITERATION in `seq 1 $PARALLELDD_ITERATIONS`; do
	mmtests_wait_token "iteration_begin"
	mmtests_activity iteration $ITERATION
		echo Dumping cache for cold cache read
		sync
		echo 3 > /proc/sys/vm/drop_caches

		echo Starting iteration $ITERATION/$PARALLELDD_ITERATIONS threads $NR_THREADS
		for INSTANCE in `seq 1 $NR_THREADS`; do
			OUTPUT_FILE=/dev/null
			if [ "$PARALLELDD_WRITEFILES" = "yes" ]; then
				OUTPUT_FILE=$SHELLPACK_DATA/output.$INSTANCE
			fi
			INPUT_FILE=$SHELLPACK_DATA/source_file
			if [ "$PARALLELDD_SPLITINPUT" = "yes" ]; then
				INPUT_FILE=${INPUT_FILE}.$INSTANCE
			fi
			eval sh /mmtests/mmtests_CI/data_collection.sh 20 $LOGDIR_RESULTS $NR_THREADS-$INSTANCE$NR_THREADS &

			$TIME_CMD -o $LOGDIR_RESULTS/time-$NR_THREADS-$INSTANCE-$ITERATION \
				dd if=$INPUT_FILE of=$OUTPUT_FILE 2> $LOGDIR_RESULTS/log-$NR_THREADS-$INSTANCE-$ITERATION &
		done

		echo Waiting on dd instances to complete
		wait
		rm -f $SHELLPACK_DATA/output.*
sync
mmtests_wait_token "iteration_end"
done
	monitor_post_hook $LOGDIR_RESULTS $NR_THREADS
done

rm $SHELLPACK_DATA/source_file*

exit $SHELLPACK_SUCCESS
